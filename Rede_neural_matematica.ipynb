{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Rede Neurais Artificiais</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vers√£o da Linguagem Python Usada Neste Jupyter Notebook: 3.13.2\n"
     ]
    }
   ],
   "source": [
    "# Vers√£o da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Vers√£o da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Matem√°tica das Redes Neurais Artificiais\n",
    "\n",
    "Este notebook tem como objetivo demonstrar a implementa√ß√£o de uma rede neural do zero, utilizando apenas conceitos matem√°ticos e a biblioteca NumPy. \n",
    "\n",
    "O foco est√° em entender os fundamentos de redes neurais sem depender de frameworks avan√ßados como TensorFlow ou PyTorch.\n",
    "\n",
    "Vamos percorrer desde a inicializa√ß√£o dos pesos at√© o treinamento e avalia√ß√£o da rede. Ao final, voc√™ ter√° uma compreens√£o clara dos c√°lculos internos de uma rede neural.\n",
    "\n",
    "### Construindo a Rede Neural com Programa√ß√£o e Matem√°tica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teremos 2 Partes:\n",
    "\n",
    "- Parte 1 - Vamos construir uma rede neural artificial somente com opera√ß√µes matem√°ticas\n",
    "- Parte 2 - Vamos treinar a rede para Prever a Ocorr√™ncia de C√¢ncer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Arquitetura de Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma rede neural t√≠pica √© constitu√≠da por um conjunto de neur√¥nios interligados, infuenciando uns aos outros formando um sistema maior, capaz de armazenar conhecimento adquirido por meio de exemplos apresentados e, assim, podendo realizar infer√™ncias sobre novos conjuntos de dados. Vejamos a arquitetura de redes neurais artificiais.\n",
    "\n",
    "As redes neurais s√£o comumente apresentadas como um grafo orientado, onde os v√©rtices s√£o os neur√¥nios e as arestas as sinapses. A dire√ß√£o das arestas informa o tipo de alimenta√ß√£o, ou seja, como os neur√¥nios s√£o alimentados (recebem sinais de entrada). As redes neurais derivam seu poder devido a sua estrutura massiva e paralela e a habilidade de aprender por experi√™ncia. Essa experi√™ncia √© transmitida por meio de exemplos obtidos do mundo real, definidos como um conjunto de caracter√≠sticas formados por dados de entrada e de sa√≠da. Se apresentamos esses dados de entrada e sa√≠da √† rede, estamos diante de aprendizagem supervsionada e caso apresentemos apenas os dados de entrada, estamos diante de aprendizagem n√£o supervisionada!\n",
    "\n",
    "O conhecimento obtido pela rede atrav√©s dos exemplos √© armazenado na forma de pesos das conex√µes, os quais ser√£o ajustados a fim de tomar decis√µes corretas a partir de novas entradas, ou seja, novas situa√ß√µes do mundo real n√£o conhecidas pela rede. O processo de ajuste dos pesos sinapticos √© realizado pelo algoritmo de aprendizagem, respons√°vel em armazenar na rede o conhecimento do mundo real obtido atraves de exemplos. Existem v√°rios algoritmos de aprendizagem, dentre eles o backpropagation que √© o algoritmo mais utilizado.\n",
    "\n",
    "![title](imagens/nnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por enquanto precisaremos somente do NumPy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Jeferson Oliveira\n",
      "\n",
      "platform: 1.0.8\n",
      "numpy   : 2.2.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vers√µes dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Jeferson Oliveira\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 - Implementando Uma Rede Neural Artificial Somente com F√≥rmulas Matem√°ticas (Sem Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa a leitura do manual em pdf no pr√≥ximo item de aprendizagem: Par√¢metros x Hiperpar√¢metros.\n",
    "\n",
    "O material esta em ingles, mas √© um material rapido sobre a matematica envolvida no algoritmo de rede neural\n",
    "\n",
    "https://arxiv.org/pdf/1905.07490.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1A - Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo a Fun√ß√£o Para Inicializa√ß√£o de Pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que a rede neural aprenda padr√µes nos dados, precisamos inicializar os pesos de maneira aleat√≥ria e atribuir valores aos bias. \n",
    "\n",
    "Isso evita que todos os neur√¥nios comecem com os mesmos valores e garante que o aprendizado ocorra de forma eficaz.\n",
    "\n",
    "Utilizaremos uma distribui√ß√£o normal para os pesos, pois isso ajuda na estabilidade do treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para inicializa√ß√£o rand√¥mica dos par√¢metros do modelo\n",
    "def inicializa_parametros(dims_camada_entrada):\n",
    "    \n",
    "    # Dicion√°rio para os par√¢metros\n",
    "    parameters = {}\n",
    "    \n",
    "    # Comprimento das dimens√µes das camadas\n",
    "    comp = len(dims_camada_entrada)\n",
    "    \n",
    "    # Loop pelo comprimento\n",
    "    for i in range(1, comp):\n",
    "        \n",
    "        # Inicializa√ß√£o da matriz de pesos\n",
    "        parameters[\"W\" + str(i)] = np.random.randn(dims_camada_entrada[i], dims_camada_entrada[i - 1]) * 0.01\n",
    "        \n",
    "        # Inicializa√ß√£o do bias\n",
    "        parameters[\"b\" + str(i)] = np.zeros((dims_camada_entrada[i], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo a Fun√ß√£o Sigm√≥ide\n",
    "\n",
    "A principal raz√£o pela qual usamos a fun√ß√£o sigm√≥ide √© porque ela permite converter n√∫meros para valores entre 0 e 1. \n",
    "\n",
    "Portanto, √© especialmente usada para modelos em que temos que prever a probabilidade como uma sa√≠da. Como a probabilidade de qualquer coisa existir apenas entre o intervalo de 0 e 1, sigmoide √© a escolha certa. Algumas caracter√≠siticas da fun√ß√£o sigm√≥ide:\n",
    "\n",
    "- A fun√ß√£o √© diferenci√°vel. Isso significa que podemos encontrar a inclina√ß√£o da curva sigm√≥ide em dois pontos.\n",
    "- A fun√ß√£o sigm√≥ide log√≠stica pode fazer com que uma rede neural fique presa no momento do treinamento.\n",
    "- A fun√ß√£o softmax √© uma fun√ß√£o de ativa√ß√£o log√≠stica mais generalizada, utilizada para a classifica√ß√£o em v√°rias classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a fun√ß√£o parecer muito abstrata ou estranha para voc√™, n√£o se preocupe muito com detalhes como o n√∫mero de Euler e ou como algu√©m criou essa fun√ß√£o. Para aqueles que n√£o s√£o conhecedores de matem√°tica, a √∫nica coisa importante sobre a fun√ß√£o sigm√≥ide √© primeiro, sua curva e, segundo, sua derivada. Aqui est√£o mais alguns detalhes:\n",
    "\n",
    "- **A fun√ß√£o sigm√≥ide produz resultados semelhantes aos da fun√ß√£o de passo (Step Function) em que a sa√≠da est√° entre 0 e 1. A curva cruza 0,5 a z = 0, e podemos definir regras para a fun√ß√£o de ativa√ß√£o, como: Se a sa√≠da do neur√¥nio sigm√≥ide for maior que ou igual a 0,5, gera 1; se a sa√≠da for menor que 0,5, gera 0.**\n",
    "\n",
    "\n",
    "- A fun√ß√£o sigm√≥ide √© suave e possui uma derivada simples de œÉ(z) * (1 - œÉ (z)), que √© diferenci√°vel em qualquer lugar da curva. \n",
    "\n",
    "\n",
    "- Se z for muito negativo, a sa√≠da ser√° aproximadamente 0; se z for muito positivo, a sa√≠da √© aproximadamente 1; mas em torno de z = 0, onde z n√£o √© muito grande nem muito pequeno, temos um desvio relativamente maior √† medida que z muda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Afinal, O Que √© Derivada?**\n",
    "\n",
    "![title](imagens/derivada.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No C√°lculo, a derivada em um ponto de uma fun√ß√£o y = f(x) representa a taxa de varia√ß√£o instant√¢nea de y em rela√ß√£o a x neste ponto. \n",
    "\n",
    "Um exemplo t√≠pico √© a fun√ß√£o velocidade que representa a taxa de varia√ß√£o (derivada) da fun√ß√£o espa√ßo. Do mesmo modo, a fun√ß√£o acelera√ß√£o √© a derivada da fun√ß√£o velocidade. Geometricamente, a derivada no ponto x = a de y = f(x) representa a inclina√ß√£o da reta tangente ao gr√°fico desta fun√ß√£o no ponto (a, f(a)).\n",
    "\n",
    "A fun√ß√£o que a cada ponto x associa a derivada neste ponto de f(x) √© chamada de fun√ß√£o derivada de f(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/derivada.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em cada ponto, a derivada de f(x) √© a tangente do √¢ngulo que a reta tangente √† curva faz em rela√ß√£o ao eixo das abscissas. A reta √© sempre tangente √† curva azul; a tangente do √¢ngulo que ela faz com o eixo das abscissas √© a derivada. Note-se que a derivada √© positiva quando verde, negativa quando vermelha, e zero quando preta.\n",
    "\n",
    "A derivada de uma fun√ß√£o y = f(x) num ponto x = x0, √© igual ao valor da tangente trigonom√©trica do √¢ngulo formado pela tangente geom√©trica √† curva representativa de y=f(x), no ponto x = x0, ou seja, a derivada √© o coeficiente angular da reta tangente ao gr√°fico da fun√ß√£o no ponto x0.\n",
    "\n",
    "A fun√ß√£o derivada √© representada por f'(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o sigm√≥ide\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo a Fun√ß√£o ReLU\n",
    "\n",
    "Para usar a descida de gradiente estoc√°stico com retropropaga√ß√£o de erros para treinar redes neurais profundas, √© necess√°ria uma fun√ß√£o de ativa√ß√£o que se assemelhe e atue como uma fun√ß√£o linear, mas √©, de fato, uma fun√ß√£o n√£o linear que permite que relacionamentos complexos nos dados sejam aprendidos.\n",
    "\n",
    "A solu√ß√£o √© usar a fun√ß√£o de ativa√ß√£o linear retificada ou ReL para abreviar. Um n√≥ ou unidade que implementa essa fun√ß√£o de ativa√ß√£o √© chamado de unidade de ativa√ß√£o linear retificada ou ReLU, para abreviar. Frequentemente, as redes que usam a fun√ß√£o retificadora para as camadas ocultas s√£o chamadas de redes retificadas.\n",
    "\n",
    "A fun√ß√£o ReLU √© definida como ùëì(ùë•) = max (0, ùë•). Normalmente, ela √© aplicada elemento a elemento √† sa√≠da de alguma outra fun√ß√£o, como um produto de vetor e matriz. \n",
    "\n",
    "A ado√ß√£o da ReLU pode ser facilmente considerada um dos marcos na revolu√ß√£o do aprendizado profundo, por ex. as t√©cnicas que agora permitem o desenvolvimento rotineiro de redes neurais muito profundas.\n",
    "\n",
    "A derivada da fun√ß√£o linear retificada tamb√©m √© f√°cil de calcular. **A derivada da fun√ß√£o de ativa√ß√£o √© necess√°ria ao atualizar os pesos de um n√≥ como parte da retropropaga√ß√£o de erro.**\n",
    "\n",
    "A derivada da fun√ß√£o √© a inclina√ß√£o. A inclina√ß√£o para valores negativos √© 0,0 e a inclina√ß√£o para valores positivos √© 1,0.\n",
    "\n",
    "Tradicionalmente, o campo das redes neurais evitou qualquer fun√ß√£o de ativa√ß√£o que n√£o fosse completamente diferenci√°vel, talvez adiando a ado√ß√£o da fun√ß√£o linear retificada e de outras fun√ß√µes lineares. Tecnicamente, n√£o podemos calcular a derivada quando a entrada √© 0,0; portanto, podemos assumir que √© zero. Este n√£o √© um problema na pr√°tica.\n",
    "\n",
    "Os gradientes das ativa√ß√µes tangentes e hiperb√≥licas s√£o menores que a por√ß√£o positiva da ReLU. Isso significa que a parte positiva √© atualizada mais rapidamente √† medida que o treinamento avan√ßa. No entanto, isso tem um custo. O gradiente 0 no lado esquerdo tem seu pr√≥prio problema, chamado \"neur√¥nios mortos\", no qual uma atualiza√ß√£o de gradiente define os valores recebidos para uma ReLU, de modo que a sa√≠da √© sempre zero; unidades ReLU modificadas, como ELU (ou Leaky ReLU, ou PReLU, etc.) podem melhorar isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/relu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de ativa√ß√£o ReLu (Rectified Linear Unit)\n",
    "def relu(Z):\n",
    "    A = abs(Z * (Z > 0))\n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/net-relu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo a Ativa√ß√£o Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opera√ß√£o de ativa√ß√£o\n",
    "# A √© a matriz com os dados de entrada\n",
    "# W √© a matriz de pesos\n",
    "# b √© o bias\n",
    "def linear_activation(A, W, b):\n",
    "    Z = np.dot(W, A) + b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o Processo de Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No forward propagation, os dados percorrem a rede desde a entrada at√© a sa√≠da final. Esse processo envolve o c√°lculo de ativa√ß√µes para cada camada oculta utilizando uma fun√ß√£o de ativa√ß√£o. \n",
    "\n",
    "Aqui utilizaremos a fun√ß√£o Sigmoid (ou ReLU, dependendo do caso), pois elas ajudam a modelar rela√ß√µes n√£o lineares entre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movimento para frente (forward)\n",
    "def forward(A_prev, W, b, activation):\n",
    "    \n",
    "    # Se a fun√ß√£o de ativa√ß√£o for Sigmoid, entramos neste bloco\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_activation(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    # Se n√£o, se for ReLu, entramos neste bloco    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_activation(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando Ativa√ß√£o e Propaga√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propaga√ß√£o para frente\n",
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    # Lista de valores anteriores (cache)\n",
    "    caches = []\n",
    "    \n",
    "    # Dados de entrada\n",
    "    A = X\n",
    "    \n",
    "    # Comprimento dos par√¢metros\n",
    "    L = len(parameters) // 2\n",
    "   \n",
    "    # Loop\n",
    "    for i in range(1, L):\n",
    "      \n",
    "        # Guarda o valor pr√©vio de A\n",
    "        A_prev = A\n",
    "        \n",
    "        # Executa o forward\n",
    "        A, cache = forward(A_prev, parameters[\"W\" + str(i)], parameters[\"b\" + str(i)], activation = \"relu\")\n",
    "        \n",
    "        # Grava o cache\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Sa√≠da na √∫ltima camada\n",
    "    A_last, cache = forward(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], activation = \"sigmoid\")\n",
    "    \n",
    "    # Grava o cache\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return(A_last, caches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo a Fun√ß√£o de Custo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/custo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de custo (ou fun√ß√£o de erro)\n",
    "def calcula_custo(A_last, Y):\n",
    "    \n",
    "    # Ajusta o shape de Y para obter seu comprimento (total de elementos)\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    # Calcula o custo comparando valor real e previso\n",
    "    custo = (-1 / m) * np.sum((Y * np.log(A_last)) + ((1 - Y) * np.log(1 - A_last)))\n",
    "    \n",
    "    # Ajusta o shape do custo\n",
    "    custo = np.squeeze(custo)\n",
    "    \n",
    "    return(custo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1B - Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O backpropagation √© o cora√ß√£o do aprendizado da rede neural. Ele calcula o gradiente da fun√ß√£o de perda em rela√ß√£o aos pesos e os ajusta utilizando o m√©todo do gradiente descendente. \n",
    "\n",
    "Esse processo garante que a rede aprenda padr√µes a cada itera√ß√£o, reduzindo gradativamente o erro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/backpropagation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo o Backward Propagation - Fun√ß√£o Sigm√≥ide Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o sigmoid para o backpropagation \n",
    "# Fazemos o c√°lculo da derivada pois n√£o queremos o valor completo da fun√ß√£o, mas sim sua varia√ß√£o\n",
    "def sigmoid_backward(da, Z):\n",
    "    \n",
    "    # Calculamos a derivada de Z\n",
    "    dg = (1 / (1 + np.exp(-Z))) * (1 - (1 / (1 + np.exp(-Z))))\n",
    "    \n",
    "    # Encontramos a mudan√ßa na derivada de z\n",
    "    dz = da * dg\n",
    "    return dz\n",
    "\n",
    "# Compare com a fun√ß√£o sigmoid do forward propagation\n",
    "# A = 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo o Backward Propagation - Fun√ß√£o ReLu Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o relu para o backpropagation \n",
    "# Fazemos o c√°lculo da derivada pois n√£o queremos o valor completo da fun√ß√£o, mas sim sua varia√ß√£o\n",
    "def relu_backward(da, Z):\n",
    "    \n",
    "    dg = 1 * ( Z >= 0)\n",
    "    dz = da * dg\n",
    "    return dz\n",
    "\n",
    "# Compare com a fun√ß√£o relu do forward propagation:\n",
    "# A = abs(Z * (Z > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo o Backward Propagation - Ativa√ß√£o Linear Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ativa√ß√£o linear para o backpropagation\n",
    "def linear_backward_function(dz, cache):\n",
    "    \n",
    "    # Recebe os valores do cache (mem√≥ria)\n",
    "    A_prev, W, b = cache\n",
    "    \n",
    "    # Shape de m\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    # Calcula a derivada de W (resultado da opera√ß√£o com dz)\n",
    "    dW = (1 / m) * np.dot(dz, A_prev.T)\n",
    "    \n",
    "    # Calcula a derivada de b (resultado da opera√ß√£o com dz)\n",
    "    db = (1 / m) * np.sum(dz, axis = 1, keepdims = True)\n",
    "    \n",
    "    # Calcula a derivada da opera√ß√£o\n",
    "    dA_prev = np.dot(W.T, dz)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo o Backward Propagation - Ativa√ß√£o Linear Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o que define o tipo de ativa√ß√£o (relu ou sigmoid)\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \n",
    "    # Extrai o cache\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    # Verifica se a ativa√ß√£o √© relu\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward_function(dZ, linear_cache)\n",
    "        \n",
    "    # Verifica se a ativa√ß√£o √© sigmoid\n",
    "    if activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward_function(dZ, linear_cache)\n",
    "        \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando Ativa√ß√£o e Retropropaga√ß√£o - Algoritmo Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo Backpropagation (calcula os gradientes para atualiza√ß√£o dos pesos)\n",
    "# AL = Valor previsto no Forward\n",
    "# Y = Valor real\n",
    "def backward_propagation(AL, Y, caches):\n",
    "    \n",
    "    # Dicion√°rio para os gradientes\n",
    "    grads = {}\n",
    "    \n",
    "    # Comprimento dos dados (que est√£o no cache)\n",
    "    L = len(caches)\n",
    "    \n",
    "    # Extrai o comprimento para o valor de m\n",
    "    m = AL.shape[1]\n",
    "    \n",
    "    # Ajusta o shape de Y\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    # Calcula a derivada da previs√£o final da rede (feita ao final do Forward Propagation)\n",
    "    dAL = -((Y / AL) - ((1 - Y) / (1 - AL)))\n",
    "    \n",
    "    # Captura o valor corrente do cache\n",
    "    current_cache = caches[L - 1]\n",
    "    \n",
    "    # Gera a lista de gradiente para os dados, os pesos e o bias\n",
    "    # Fazemos isso uma vez, pois estamos na parte final da rede, iniciando o caminho de volta\n",
    "    grads[\"dA\" + str(L - 1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    \n",
    "    # Loop para calcular a derivada durante as ativa√ß√µes lineares com a relu\n",
    "    for l in reversed(range(L - 1)):\n",
    "        \n",
    "        # Cache atual\n",
    "        current_cache = caches[l]\n",
    "        \n",
    "        # Calcula as derivadas\n",
    "        dA_prev, dW, db = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        \n",
    "        # Alimenta os gradientes na lista, usando o √≠ndice respectivo\n",
    "        grads[\"dA\" + str(l)] = dA_prev\n",
    "        grads[\"dW\" + str(l + 1)] = dW\n",
    "        grads[\"db\" + str(l + 1)] = db\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradientes e Atualiza√ß√£o dos Pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de atualiza√ß√£o de pesos\n",
    "def atualiza_pesos(parameters, grads, learning_rate):\n",
    "    \n",
    "    # Comprimento da estrutura de dados com os par√¢metros (pesos e bias)\n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    # Loop para atualiza√ß√£o dos pesos\n",
    "    for l in range(L):\n",
    "        \n",
    "        # Atualiza√ß√£o dos pesos\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - (learning_rate * grads[\"dW\" + str(l + 1)])\n",
    "        \n",
    "        # Atualiza√ß√£o do bias\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - (learning_rate * grads[\"db\" + str(l + 1)])\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando a Rede Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo completo da rede neural\n",
    "def modeloNN(X, Y, dims_camada_entrada, learning_rate = 0.0075, num_iterations = 100):\n",
    "    \n",
    "    # Lista para receber o custo a cada √©poca de treinamento\n",
    "    custos = []\n",
    "    \n",
    "    # Inicializa os par√¢metros\n",
    "    parametros = inicializa_parametros(dims_camada_entrada)\n",
    "    \n",
    "    # Loop pelo n√∫mero de itera√ß√µes (√©pocas)\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Forward Propagation\n",
    "        AL, caches = forward_propagation(X, parametros)\n",
    "        \n",
    "        # Calcula o custo\n",
    "        custo = calcula_custo(AL, Y)\n",
    "        \n",
    "        # Backward Propagation\n",
    "        # Nota: ao inv√©s de AL e Y, poder√≠amos passar somente o valor do custo\n",
    "        # Estamos passando o valor de AL e Y para fique claro didaticamente o que est√° sendo feito\n",
    "        gradientes = backward_propagation(AL, Y, caches)\n",
    "        \n",
    "        # Atualiza os pesos\n",
    "        parametros = atualiza_pesos(parametros, gradientes, learning_rate)\n",
    "        \n",
    "        # Print do valor intermedi√°rio do custo\n",
    "        # A redu√ß√£o do custo indica o aprendizado do modelo\n",
    "        if i % 10 == 0:\n",
    "            print(\"Custo Ap√≥s \" + str(i) + \" itera√ß√µes √© \" + str(custo))\n",
    "            custos.append(custo)\n",
    "            \n",
    "    return parametros, custos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para fazer as previs√µes\n",
    "# N√£o precisamos do Backpropagation pois ao fazer previs√µes como o modelo treinado, \n",
    "# teremos os melhores valores de pesos (parametros)\n",
    "def predict(X, parametros):\n",
    "    AL, caches = forward_propagation(X, parametros)\n",
    "    return AL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 - Vamos treinar a rede para Prever a Ocorr√™ncia de C√¢ncer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Projeto 4 - Usando a Rede Neural Para Prever a Ocorr√™ncia de C√¢ncer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Jeferson Oliveira\n",
      "\n",
      "pandas    : 2.2.3\n",
      "platform  : 1.0.8\n",
      "sklearn   : 1.6.1\n",
      "matplotlib: 3.10.0\n",
      "numpy     : 2.2.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vers√µes dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Jeferson Oliveira\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os Dados\n",
    "\n",
    "https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos o objeto completo\n",
    "temp = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo do objeto\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]], shape=(569, 30)),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 569\\n\\n:Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n:Attribute Information:\\n    - radius (mean of distances from center to points on the perimeter)\\n    - texture (standard deviation of gray-scale values)\\n    - perimeter\\n    - area\\n    - smoothness (local variation in radius lengths)\\n    - compactness (perimeter^2 / area - 1.0)\\n    - concavity (severity of concave portions of the contour)\\n    - concave points (number of concave portions of the contour)\\n    - symmetry\\n    - fractal dimension (\"coastline approximation\" - 1)\\n\\n    The mean, standard error, and \"worst\" or largest (mean of the three\\n    worst/largest values) of these features were computed for each image,\\n    resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n    10 is Radius SE, field 20 is Worst Radius.\\n\\n    - class:\\n            - WDBC-Malignant\\n            - WDBC-Benign\\n\\n:Summary Statistics:\\n\\n===================================== ====== ======\\n                                        Min    Max\\n===================================== ====== ======\\nradius (mean):                        6.981  28.11\\ntexture (mean):                       9.71   39.28\\nperimeter (mean):                     43.79  188.5\\narea (mean):                          143.5  2501.0\\nsmoothness (mean):                    0.053  0.163\\ncompactness (mean):                   0.019  0.345\\nconcavity (mean):                     0.0    0.427\\nconcave points (mean):                0.0    0.201\\nsymmetry (mean):                      0.106  0.304\\nfractal dimension (mean):             0.05   0.097\\nradius (standard error):              0.112  2.873\\ntexture (standard error):             0.36   4.885\\nperimeter (standard error):           0.757  21.98\\narea (standard error):                6.802  542.2\\nsmoothness (standard error):          0.002  0.031\\ncompactness (standard error):         0.002  0.135\\nconcavity (standard error):           0.0    0.396\\nconcave points (standard error):      0.0    0.053\\nsymmetry (standard error):            0.008  0.079\\nfractal dimension (standard error):   0.001  0.03\\nradius (worst):                       7.93   36.04\\ntexture (worst):                      12.02  49.54\\nperimeter (worst):                    50.41  251.2\\narea (worst):                         185.2  4254.0\\nsmoothness (worst):                   0.071  0.223\\ncompactness (worst):                  0.027  1.058\\nconcavity (worst):                    0.0    1.252\\nconcave points (worst):               0.0    0.291\\nsymmetry (worst):                     0.156  0.664\\nfractal dimension (worst):            0.055  0.208\\n===================================== ====== ======\\n\\n:Missing Attribute Values: None\\n\\n:Class Distribution: 212 - Malignant, 357 - Benign\\n\\n:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n:Donor: Nick Street\\n\\n:Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. dropdown:: References\\n\\n  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\\n    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\\n    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n    San Jose, CA, 1993.\\n  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\\n    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\\n    July-August 1995.\\n  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\\n    163-171.\\n',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o objeto\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos o dataset\n",
    "dados = pd.DataFrame(columns = load_breast_cancer()[\"feature_names\"], data = load_breast_cancer()[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                False\n",
       "mean texture               False\n",
       "mean perimeter             False\n",
       "mean area                  False\n",
       "mean smoothness            False\n",
       "mean compactness           False\n",
       "mean concavity             False\n",
       "mean concave points        False\n",
       "mean symmetry              False\n",
       "mean fractal dimension     False\n",
       "radius error               False\n",
       "texture error              False\n",
       "perimeter error            False\n",
       "area error                 False\n",
       "smoothness error           False\n",
       "compactness error          False\n",
       "concavity error            False\n",
       "concave points error       False\n",
       "symmetry error             False\n",
       "fractal dimension error    False\n",
       "worst radius               False\n",
       "worst texture              False\n",
       "worst perimeter            False\n",
       "worst area                 False\n",
       "worst smoothness           False\n",
       "worst compactness          False\n",
       "worst concavity            False\n",
       "worst concave points       False\n",
       "worst symmetry             False\n",
       "worst fractal dimension    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica se temos valores ausentes\n",
    "dados.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa a vari√°vel target\n",
    "target = load_breast_cancer()[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a vari√°vel\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de registros por classe - C√¢ncer Benigno\n",
    "np.count_nonzero(target == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de registros por classe - C√¢ncer Maligno\n",
    "np.count_nonzero(target == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos extrair os labels\n",
    "\n",
    "# Dicion√°rio para os labels\n",
    "labels = {}\n",
    "\n",
    "# Nomes das classes da vari√°vel target\n",
    "target_names = load_breast_cancer()[\"target_names\"]\n",
    "\n",
    "# Mapeamento\n",
    "for i in range(len(target_names)):\n",
    "    labels.update({i:target_names[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: np.str_('malignant'), 1: np.str_('benign')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os labels\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora preparamos as vari√°veis preditoras em X\n",
    "X = np.array(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]], shape=(569, 30))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados de entrada\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos os dados de entrada e sa√≠da em treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, target, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 30)\n",
      "(483,)\n"
     ]
    }
   ],
   "source": [
    "# Shape dos dados de treino\n",
    "print(X_treino.shape)\n",
    "print(y_treino.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 30)\n",
      "(86,)\n"
     ]
    }
   ],
   "source": [
    "# Shape dos dados de teste\n",
    "print(X_teste.shape)\n",
    "print(y_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o shape dos dados de entrada\n",
    "X_treino = X_treino.T\n",
    "X_teste = X_teste.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 483)\n",
      "(30, 86)\n"
     ]
    }
   ],
   "source": [
    "print(X_treino.shape)\n",
    "print(X_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos ajustar tamb√©m os dados de sa√≠da\n",
    "y_treino = y_treino.reshape(1, len(y_treino))\n",
    "y_teste = y_teste.reshape(1, len(y_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 483)\n",
      "(1, 86)\n"
     ]
    }
   ],
   "source": [
    "print(y_treino.shape)\n",
    "print(y_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vari√°vel com as dimens√µes de entrada para oo n√∫mero de neur√¥nios \n",
    "dims_camada_entrada = [X_treino.shape[0], 50, 20, 5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 50, 20, 5, 1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims_camada_entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ap√≥s definir todas as fun√ß√µes da rede, precisamos trein√°-la. Isso envolve iterar v√°rias vezes sobre os dados, ajustando os pesos para minimizar a fun√ß√£o de perda. \n",
    "\n",
    "Durante a avalia√ß√£o, aplicamos os dados de teste para verificar se a rede generalizou bem ou se est√° apenas decorando os exemplos de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o Treinamento.\n",
      "\n",
      "Custo Ap√≥s 0 itera√ß√µes √© 0.6931493840781573\n",
      "Custo Ap√≥s 10 itera√ß√µes √© 0.6920290945093092\n",
      "Custo Ap√≥s 20 itera√ß√µes √© 0.6909497872392654\n",
      "Custo Ap√≥s 30 itera√ß√µes √© 0.689909970535485\n",
      "Custo Ap√≥s 40 itera√ß√µes √© 0.688908208653603\n",
      "Custo Ap√≥s 50 itera√ß√µes √© 0.6879430868636165\n",
      "Custo Ap√≥s 60 itera√ß√µes √© 0.6870132222761752\n",
      "Custo Ap√≥s 70 itera√ß√µes √© 0.6861172868989424\n",
      "Custo Ap√≥s 80 itera√ß√µes √© 0.6852539924818695\n",
      "Custo Ap√≥s 90 itera√ß√µes √© 0.6844221012252018\n",
      "Custo Ap√≥s 100 itera√ß√µes √© 0.6836204232651194\n",
      "Custo Ap√≥s 110 itera√ß√µes √© 0.6828477970640779\n",
      "Custo Ap√≥s 120 itera√ß√µes √© 0.6821031024115783\n",
      "Custo Ap√≥s 130 itera√ß√µes √© 0.6813852737420076\n",
      "Custo Ap√≥s 140 itera√ß√µes √© 0.6806932673462727\n",
      "Custo Ap√≥s 150 itera√ß√µes √© 0.6800260395871058\n",
      "Custo Ap√≥s 160 itera√ß√µes √© 0.6793825820261161\n",
      "Custo Ap√≥s 170 itera√ß√µes √© 0.6787619330845421\n",
      "Custo Ap√≥s 180 itera√ß√µes √© 0.6781631855163909\n",
      "Custo Ap√≥s 190 itera√ß√µes √© 0.6775856376977076\n",
      "Custo Ap√≥s 200 itera√ß√µes √© 0.6770286327165315\n",
      "Custo Ap√≥s 210 itera√ß√µes √© 0.676491266651878\n",
      "Custo Ap√≥s 220 itera√ß√µes √© 0.6759726760058379\n",
      "Custo Ap√≥s 230 itera√ß√µes √© 0.6754719938610222\n",
      "Custo Ap√≥s 240 itera√ß√µes √© 0.6749884166367105\n",
      "Custo Ap√≥s 250 itera√ß√µes √© 0.6745211464809768\n",
      "Custo Ap√≥s 260 itera√ß√µes √© 0.674069411328607\n",
      "Custo Ap√≥s 270 itera√ß√µes √© 0.673632456123663\n",
      "Custo Ap√≥s 280 itera√ß√µes √© 0.6732095036409897\n",
      "Custo Ap√≥s 290 itera√ß√µes √© 0.6727997872335151\n",
      "Custo Ap√≥s 300 itera√ß√µes √© 0.6724025032648697\n",
      "Custo Ap√≥s 310 itera√ß√µes √© 0.6720168298818163\n",
      "Custo Ap√≥s 320 itera√ß√µes √© 0.6716418999383625\n",
      "Custo Ap√≥s 330 itera√ß√µes √© 0.6712768014603322\n",
      "Custo Ap√≥s 340 itera√ß√µes √© 0.6709205490930524\n",
      "Custo Ap√≥s 350 itera√ß√µes √© 0.670572070763052\n",
      "Custo Ap√≥s 360 itera√ß√µes √© 0.6702301706761491\n",
      "Custo Ap√≥s 370 itera√ß√µes √© 0.6698934819899748\n",
      "Custo Ap√≥s 380 itera√ß√µes √© 0.6695604253358909\n",
      "Custo Ap√≥s 390 itera√ß√µes √© 0.6692291174376198\n",
      "Custo Ap√≥s 400 itera√ß√µes √© 0.6688972906436763\n",
      "Custo Ap√≥s 410 itera√ß√µes √© 0.6685621526657215\n",
      "Custo Ap√≥s 420 itera√ß√µes √© 0.6682202329162722\n",
      "Custo Ap√≥s 430 itera√ß√µes √© 0.6678670680542387\n",
      "Custo Ap√≥s 440 itera√ß√µes √© 0.667496497607119\n",
      "Custo Ap√≥s 450 itera√ß√µes √© 0.667100350060845\n",
      "Custo Ap√≥s 460 itera√ß√µes √© 0.6666672643458673\n",
      "Custo Ap√≥s 470 itera√ß√µes √© 0.6661808730598414\n",
      "Custo Ap√≥s 480 itera√ß√µes √© 0.6656172462719514\n",
      "Custo Ap√≥s 490 itera√ß√µes √© 0.6649419603038416\n",
      "Custo Ap√≥s 500 itera√ß√µes √© 0.6641006409946484\n",
      "Custo Ap√≥s 510 itera√ß√µes √© 0.6630047740005384\n",
      "Custo Ap√≥s 520 itera√ß√µes √© 0.6615073079284072\n",
      "Custo Ap√≥s 530 itera√ß√µes √© 0.6593545465407853\n",
      "Custo Ap√≥s 540 itera√ß√µes √© 0.6561002788473098\n",
      "Custo Ap√≥s 550 itera√ß√µes √© 0.6509858351027973\n",
      "Custo Ap√≥s 560 itera√ß√µes √© 0.6429852777481497\n",
      "Custo Ap√≥s 570 itera√ß√µes √© 0.6319945306531859\n",
      "Custo Ap√≥s 580 itera√ß√µes √© 0.6216069788198798\n",
      "Custo Ap√≥s 590 itera√ß√µes √© 0.6157028735583877\n",
      "Custo Ap√≥s 600 itera√ß√µes √© 0.6123784638939872\n",
      "Custo Ap√≥s 610 itera√ß√µes √© 0.6095372413872391\n",
      "Custo Ap√≥s 620 itera√ß√µes √© 0.6067185827512146\n",
      "Custo Ap√≥s 630 itera√ß√µes √© 0.6038644276877017\n",
      "Custo Ap√≥s 640 itera√ß√µes √© 0.6009614224952592\n",
      "Custo Ap√≥s 650 itera√ß√µes √© 0.5979981347202113\n",
      "Custo Ap√≥s 660 itera√ß√µes √© 0.5949604317689812\n",
      "Custo Ap√≥s 670 itera√ß√µes √© 0.591830746112882\n",
      "Custo Ap√≥s 680 itera√ß√µes √© 0.5885862763349162\n",
      "Custo Ap√≥s 690 itera√ß√µes √© 0.5851974635349267\n",
      "Custo Ap√≥s 700 itera√ß√µes √© 0.5816224293392773\n",
      "Custo Ap√≥s 710 itera√ß√µes √© 0.5778036619801362\n",
      "Custo Ap√≥s 720 itera√ß√µes √© 0.5736820161215094\n",
      "Custo Ap√≥s 730 itera√ß√µes √© 0.5691564673674021\n",
      "Custo Ap√≥s 740 itera√ß√µes √© 0.5640830742516635\n",
      "Custo Ap√≥s 750 itera√ß√µes √© 0.558261203896914\n",
      "Custo Ap√≥s 760 itera√ß√µes √© 0.5514186501022277\n",
      "Custo Ap√≥s 770 itera√ß√µes √© 0.543191404392549\n",
      "Custo Ap√≥s 780 itera√ß√µes √© 0.5330545534533473\n",
      "Custo Ap√≥s 790 itera√ß√µes √© 0.5204586438540165\n",
      "Custo Ap√≥s 800 itera√ß√µes √© 0.5050099267178639\n",
      "Custo Ap√≥s 810 itera√ß√µes √© 0.4866207238220247\n",
      "Custo Ap√≥s 820 itera√ß√µes √© 0.4662767429539406\n",
      "Custo Ap√≥s 830 itera√ß√µes √© 0.44776016762224913\n",
      "Custo Ap√≥s 840 itera√ß√µes √© 0.4904401379528455\n",
      "Custo Ap√≥s 850 itera√ß√µes √© 0.4749804816097051\n",
      "Custo Ap√≥s 860 itera√ß√µes √© 0.46210469445860164\n",
      "Custo Ap√≥s 870 itera√ß√µes √© 0.45386138075314936\n",
      "Custo Ap√≥s 880 itera√ß√µes √© 0.44514023644201584\n",
      "Custo Ap√≥s 890 itera√ß√µes √© 0.43801846470567257\n",
      "Custo Ap√≥s 900 itera√ß√µes √© 0.42902037137357146\n",
      "Custo Ap√≥s 910 itera√ß√µes √© 0.42188875928393726\n",
      "Custo Ap√≥s 920 itera√ß√µes √© 0.4140260712138716\n",
      "Custo Ap√≥s 930 itera√ß√µes √© 0.40868503959039604\n",
      "Custo Ap√≥s 940 itera√ß√µes √© 0.40315304391948015\n",
      "Custo Ap√≥s 950 itera√ß√µes √© 0.39927605559854323\n",
      "Custo Ap√≥s 960 itera√ß√µes √© 0.3943331244039795\n",
      "Custo Ap√≥s 970 itera√ß√µes √© 0.39079644234267835\n",
      "Custo Ap√≥s 980 itera√ß√µes √© 0.3886111937949199\n",
      "Custo Ap√≥s 990 itera√ß√µes √© 0.38517261769049277\n",
      "Custo Ap√≥s 1000 itera√ß√µes √© 0.380297096611562\n",
      "Custo Ap√≥s 1010 itera√ß√µes √© 0.37738944017307585\n",
      "Custo Ap√≥s 1020 itera√ß√µes √© 0.37346565210325483\n",
      "Custo Ap√≥s 1030 itera√ß√µes √© 0.37246179468798496\n",
      "Custo Ap√≥s 1040 itera√ß√µes √© 0.3697309805804461\n",
      "Custo Ap√≥s 1050 itera√ß√µes √© 0.3676067172745954\n",
      "Custo Ap√≥s 1060 itera√ß√µes √© 0.3642490631098486\n",
      "Custo Ap√≥s 1070 itera√ß√µes √© 0.3619624409842113\n",
      "Custo Ap√≥s 1080 itera√ß√µes √© 0.3582774033325965\n",
      "Custo Ap√≥s 1090 itera√ß√µes √© 0.3561224214752046\n",
      "Custo Ap√≥s 1100 itera√ß√µes √© 0.3525174664092406\n",
      "Custo Ap√≥s 1110 itera√ß√µes √© 0.348780058820252\n",
      "Custo Ap√≥s 1120 itera√ß√µes √© 0.34624300401105024\n",
      "Custo Ap√≥s 1130 itera√ß√µes √© 0.34601299953144843\n",
      "Custo Ap√≥s 1140 itera√ß√µes √© 0.3426849706031251\n",
      "Custo Ap√≥s 1150 itera√ß√µes √© 0.340943697271967\n",
      "Custo Ap√≥s 1160 itera√ß√µes √© 0.3382000190682521\n",
      "Custo Ap√≥s 1170 itera√ß√µes √© 0.33775144210966684\n",
      "Custo Ap√≥s 1180 itera√ß√µes √© 0.33666594134262445\n",
      "Custo Ap√≥s 1190 itera√ß√µes √© 0.33399422767011927\n",
      "Custo Ap√≥s 1200 itera√ß√µes √© 0.3341629206854159\n",
      "Custo Ap√≥s 1210 itera√ß√µes √© 0.3301279784612168\n",
      "Custo Ap√≥s 1220 itera√ß√µes √© 0.3303239543608008\n",
      "Custo Ap√≥s 1230 itera√ß√µes √© 0.3278122382752972\n",
      "Custo Ap√≥s 1240 itera√ß√µes √© 0.3269917166479736\n",
      "Custo Ap√≥s 1250 itera√ß√µes √© 0.32529980441678297\n",
      "Custo Ap√≥s 1260 itera√ß√µes √© 0.32344686137480105\n",
      "Custo Ap√≥s 1270 itera√ß√µes √© 0.32306545733944714\n",
      "Custo Ap√≥s 1280 itera√ß√µes √© 0.322084511631996\n",
      "Custo Ap√≥s 1290 itera√ß√µes √© 0.32188772079321365\n",
      "Custo Ap√≥s 1300 itera√ß√µes √© 0.31794336207768137\n",
      "Custo Ap√≥s 1310 itera√ß√µes √© 0.3189380663951815\n",
      "Custo Ap√≥s 1320 itera√ß√µes √© 0.3178066521948016\n",
      "Custo Ap√≥s 1330 itera√ß√µes √© 0.31649267640381745\n",
      "Custo Ap√≥s 1340 itera√ß√µes √© 0.31405678588891556\n",
      "Custo Ap√≥s 1350 itera√ß√µes √© 0.31376106439611945\n",
      "Custo Ap√≥s 1360 itera√ß√µes √© 0.31221630019492774\n",
      "Custo Ap√≥s 1370 itera√ß√µes √© 0.31210907156590134\n",
      "Custo Ap√≥s 1380 itera√ß√µes √© 0.3103460426970806\n",
      "Custo Ap√≥s 1390 itera√ß√µes √© 0.3101307661269934\n",
      "Custo Ap√≥s 1400 itera√ß√µes √© 0.30698520499015536\n",
      "Custo Ap√≥s 1410 itera√ß√µes √© 0.3091067008331583\n",
      "Custo Ap√≥s 1420 itera√ß√µes √© 0.30604203423907766\n",
      "Custo Ap√≥s 1430 itera√ß√µes √© 0.3046045089281539\n",
      "Custo Ap√≥s 1440 itera√ß√µes √© 0.3051238114191379\n",
      "Custo Ap√≥s 1450 itera√ß√µes √© 0.30251771007400374\n",
      "Custo Ap√≥s 1460 itera√ß√µes √© 0.3032137737265493\n",
      "Custo Ap√≥s 1470 itera√ß√µes √© 0.3028637312141208\n",
      "Custo Ap√≥s 1480 itera√ß√µes √© 0.3014878256265464\n",
      "Custo Ap√≥s 1490 itera√ß√µes √© 0.2991722104166601\n",
      "Custo Ap√≥s 1500 itera√ß√µes √© 0.2982647686748374\n",
      "Custo Ap√≥s 1510 itera√ß√µes √© 0.2980317540199441\n",
      "Custo Ap√≥s 1520 itera√ß√µes √© 0.2905551565233058\n",
      "Custo Ap√≥s 1530 itera√ß√µes √© 0.289493724129899\n",
      "Custo Ap√≥s 1540 itera√ß√µes √© 0.2884092973502655\n",
      "Custo Ap√≥s 1550 itera√ß√µes √© 0.28739909906004707\n",
      "Custo Ap√≥s 1560 itera√ß√µes √© 0.28596599477133083\n",
      "Custo Ap√≥s 1570 itera√ß√µes √© 0.2857593862692953\n",
      "Custo Ap√≥s 1580 itera√ß√µes √© 0.2846969403224999\n",
      "Custo Ap√≥s 1590 itera√ß√µes √© 0.28501264523997544\n",
      "Custo Ap√≥s 1600 itera√ß√µes √© 0.2853595043824203\n",
      "Custo Ap√≥s 1610 itera√ß√µes √© 0.28383576143875083\n",
      "Custo Ap√≥s 1620 itera√ß√µes √© 0.2817062238690192\n",
      "Custo Ap√≥s 1630 itera√ß√µes √© 0.2824851704366189\n",
      "Custo Ap√≥s 1640 itera√ß√µes √© 0.28996665297696333\n",
      "Custo Ap√≥s 1650 itera√ß√µes √© 0.28895866409359106\n",
      "Custo Ap√≥s 1660 itera√ß√µes √© 0.2868779526276226\n",
      "Custo Ap√≥s 1670 itera√ß√µes √© 0.2846557948488263\n",
      "Custo Ap√≥s 1680 itera√ß√µes √© 0.2798782624168282\n",
      "Custo Ap√≥s 1690 itera√ß√µes √© 0.2765894649672903\n",
      "Custo Ap√≥s 1700 itera√ß√µes √© 0.27615690697846257\n",
      "Custo Ap√≥s 1710 itera√ß√µes √© 0.2736964187824554\n",
      "Custo Ap√≥s 1720 itera√ß√µes √© 0.2748147294355417\n",
      "Custo Ap√≥s 1730 itera√ß√µes √© 0.27440223373644035\n",
      "Custo Ap√≥s 1740 itera√ß√µes √© 0.273026105179604\n",
      "Custo Ap√≥s 1750 itera√ß√µes √© 0.2757784531614402\n",
      "Custo Ap√≥s 1760 itera√ß√µes √© 0.2793200188722415\n",
      "Custo Ap√≥s 1770 itera√ß√µes √© 0.2779226578413563\n",
      "Custo Ap√≥s 1780 itera√ß√µes √© 0.2774419215156212\n",
      "Custo Ap√≥s 1790 itera√ß√µes √© 0.27499633348702746\n",
      "Custo Ap√≥s 1800 itera√ß√µes √© 0.26889099555310353\n",
      "Custo Ap√≥s 1810 itera√ß√µes √© 0.26755975680492217\n",
      "Custo Ap√≥s 1820 itera√ß√µes √© 0.2684318931243295\n",
      "Custo Ap√≥s 1830 itera√ß√µes √© 0.2709803737781394\n",
      "Custo Ap√≥s 1840 itera√ß√µes √© 0.270256671334683\n",
      "Custo Ap√≥s 1850 itera√ß√µes √© 0.2700719061111734\n",
      "Custo Ap√≥s 1860 itera√ß√µes √© 0.26867062956686627\n",
      "Custo Ap√≥s 1870 itera√ß√µes √© 0.2695968160321666\n",
      "Custo Ap√≥s 1880 itera√ß√µes √© 0.2679333705368539\n",
      "Custo Ap√≥s 1890 itera√ß√µes √© 0.26365907957756907\n",
      "Custo Ap√≥s 1900 itera√ß√µes √© 0.2654508522539648\n",
      "Custo Ap√≥s 1910 itera√ß√µes √© 0.2642335195761695\n",
      "Custo Ap√≥s 1920 itera√ß√µes √© 0.26276699657748903\n",
      "Custo Ap√≥s 1930 itera√ß√µes √© 0.26263955020465723\n",
      "Custo Ap√≥s 1940 itera√ß√µes √© 0.26142532915969185\n",
      "Custo Ap√≥s 1950 itera√ß√µes √© 0.26521637034725637\n",
      "Custo Ap√≥s 1960 itera√ß√µes √© 0.2641022095073758\n",
      "Custo Ap√≥s 1970 itera√ß√µes √© 0.2630479297906749\n",
      "Custo Ap√≥s 1980 itera√ß√µes √© 0.2581169727208021\n",
      "Custo Ap√≥s 1990 itera√ß√µes √© 0.2582729501677508\n",
      "Custo Ap√≥s 2000 itera√ß√µes √© 0.26230284945930354\n",
      "Custo Ap√≥s 2010 itera√ß√µes √© 0.26264368868362037\n",
      "Custo Ap√≥s 2020 itera√ß√µes √© 0.25865275383124947\n",
      "Custo Ap√≥s 2030 itera√ß√µes √© 0.2581213982436648\n",
      "Custo Ap√≥s 2040 itera√ß√µes √© 0.26000205813356314\n",
      "Custo Ap√≥s 2050 itera√ß√µes √© 0.2581685624025185\n",
      "Custo Ap√≥s 2060 itera√ß√µes √© 0.25523576984617263\n",
      "Custo Ap√≥s 2070 itera√ß√µes √© 0.25839736466569324\n",
      "Custo Ap√≥s 2080 itera√ß√µes √© 0.2557945349952854\n",
      "Custo Ap√≥s 2090 itera√ß√µes √© 0.2558547751514471\n",
      "Custo Ap√≥s 2100 itera√ß√µes √© 0.25645854207132773\n",
      "Custo Ap√≥s 2110 itera√ß√µes √© 0.25262114231683064\n",
      "Custo Ap√≥s 2120 itera√ß√µes √© 0.25376394398265023\n",
      "Custo Ap√≥s 2130 itera√ß√µes √© 0.2592529644079495\n",
      "Custo Ap√≥s 2140 itera√ß√µes √© 0.25677710297648004\n",
      "Custo Ap√≥s 2150 itera√ß√µes √© 0.2511570559873068\n",
      "Custo Ap√≥s 2160 itera√ß√µes √© 0.2512262029730508\n",
      "Custo Ap√≥s 2170 itera√ß√µes √© 0.25777094867944395\n",
      "Custo Ap√≥s 2180 itera√ß√µes √© 0.2570245615764003\n",
      "Custo Ap√≥s 2190 itera√ß√µes √© 0.2542521261989121\n",
      "Custo Ap√≥s 2200 itera√ß√µes √© 0.24820096531233313\n",
      "Custo Ap√≥s 2210 itera√ß√µes √© 0.24782997320253444\n",
      "Custo Ap√≥s 2220 itera√ß√µes √© 0.2515295066622097\n",
      "Custo Ap√≥s 2230 itera√ß√µes √© 0.25368290983820874\n",
      "Custo Ap√≥s 2240 itera√ß√µes √© 0.24872780179389986\n",
      "Custo Ap√≥s 2250 itera√ß√µes √© 0.24680995281547702\n",
      "Custo Ap√≥s 2260 itera√ß√µes √© 0.24826580307142757\n",
      "Custo Ap√≥s 2270 itera√ß√µes √© 0.2513014431910348\n",
      "Custo Ap√≥s 2280 itera√ß√µes √© 0.24595781140710146\n",
      "Custo Ap√≥s 2290 itera√ß√µes √© 0.24727619546748025\n",
      "Custo Ap√≥s 2300 itera√ß√µes √© 0.2491748478127592\n",
      "Custo Ap√≥s 2310 itera√ß√µes √© 0.2459474987364073\n",
      "Custo Ap√≥s 2320 itera√ß√µes √© 0.24483292455536682\n",
      "Custo Ap√≥s 2330 itera√ß√µes √© 0.24733698163587758\n",
      "Custo Ap√≥s 2340 itera√ß√µes √© 0.24510888094459857\n",
      "Custo Ap√≥s 2350 itera√ß√µes √© 0.24159879639020196\n",
      "Custo Ap√≥s 2360 itera√ß√µes √© 0.24503577222011674\n",
      "Custo Ap√≥s 2370 itera√ß√µes √© 0.24579676091036218\n",
      "Custo Ap√≥s 2380 itera√ß√µes √© 0.24455248533884782\n",
      "Custo Ap√≥s 2390 itera√ß√µes √© 0.2435414993561905\n",
      "Custo Ap√≥s 2400 itera√ß√µes √© 0.24051711487094724\n",
      "Custo Ap√≥s 2410 itera√ß√µes √© 0.24492236937083947\n",
      "Custo Ap√≥s 2420 itera√ß√µes √© 0.24479123757035845\n",
      "Custo Ap√≥s 2430 itera√ß√µes √© 0.2423998286776801\n",
      "Custo Ap√≥s 2440 itera√ß√µes √© 0.2387434061130835\n",
      "Custo Ap√≥s 2450 itera√ß√µes √© 0.24116675247368563\n",
      "Custo Ap√≥s 2460 itera√ß√µes √© 0.2455499019189227\n",
      "Custo Ap√≥s 2470 itera√ß√µes √© 0.24189969272053363\n",
      "Custo Ap√≥s 2480 itera√ß√µes √© 0.24189699961277947\n",
      "Custo Ap√≥s 2490 itera√ß√µes √© 0.242473765112517\n",
      "Custo Ap√≥s 2500 itera√ß√µes √© 0.23964350017604086\n",
      "Custo Ap√≥s 2510 itera√ß√µes √© 0.23705680539854815\n",
      "Custo Ap√≥s 2520 itera√ß√µes √© 0.23733052566193125\n",
      "Custo Ap√≥s 2530 itera√ß√µes √© 0.24336009681740178\n",
      "Custo Ap√≥s 2540 itera√ß√µes √© 0.24630549914854455\n",
      "Custo Ap√≥s 2550 itera√ß√µes √© 0.2402112960718082\n",
      "Custo Ap√≥s 2560 itera√ß√µes √© 0.23982511987229727\n",
      "Custo Ap√≥s 2570 itera√ß√µes √© 0.23771434164992689\n",
      "Custo Ap√≥s 2580 itera√ß√µes √© 0.23470978697375658\n",
      "Custo Ap√≥s 2590 itera√ß√µes √© 0.23503253228038679\n",
      "Custo Ap√≥s 2600 itera√ß√µes √© 0.23455756085940888\n",
      "Custo Ap√≥s 2610 itera√ß√µes √© 0.23438662226448984\n",
      "Custo Ap√≥s 2620 itera√ß√µes √© 0.2334425220414711\n",
      "Custo Ap√≥s 2630 itera√ß√µes √© 0.23351688356580394\n",
      "Custo Ap√≥s 2640 itera√ß√µes √© 0.2401194497006077\n",
      "Custo Ap√≥s 2650 itera√ß√µes √© 0.24283363784014386\n",
      "Custo Ap√≥s 2660 itera√ß√µes √© 0.23762904748525943\n",
      "Custo Ap√≥s 2670 itera√ß√µes √© 0.2357442124059046\n",
      "Custo Ap√≥s 2680 itera√ß√µes √© 0.23738772619099344\n",
      "Custo Ap√≥s 2690 itera√ß√µes √© 0.2360035964150802\n",
      "Custo Ap√≥s 2700 itera√ß√µes √© 0.23405282753836434\n",
      "Custo Ap√≥s 2710 itera√ß√µes √© 0.2315901442528955\n",
      "Custo Ap√≥s 2720 itera√ß√µes √© 0.2313050104180182\n",
      "Custo Ap√≥s 2730 itera√ß√µes √© 0.23597756225896074\n",
      "Custo Ap√≥s 2740 itera√ß√µes √© 0.23516362398197582\n",
      "Custo Ap√≥s 2750 itera√ß√µes √© 0.23488603913369469\n",
      "Custo Ap√≥s 2760 itera√ß√µes √© 0.23393552189043051\n",
      "Custo Ap√≥s 2770 itera√ß√µes √© 0.23347183595525442\n",
      "Custo Ap√≥s 2780 itera√ß√µes √© 0.23342719913517418\n",
      "Custo Ap√≥s 2790 itera√ß√µes √© 0.2339672857548932\n",
      "Custo Ap√≥s 2800 itera√ß√µes √© 0.23393784733864775\n",
      "Custo Ap√≥s 2810 itera√ß√µes √© 0.23289592875490395\n",
      "Custo Ap√≥s 2820 itera√ß√µes √© 0.23329694831329661\n",
      "Custo Ap√≥s 2830 itera√ß√µes √© 0.2333830798019887\n",
      "Custo Ap√≥s 2840 itera√ß√µes √© 0.23249210722094035\n",
      "Custo Ap√≥s 2850 itera√ß√µes √© 0.23077574279017235\n",
      "Custo Ap√≥s 2860 itera√ß√µes √© 0.23082919218962283\n",
      "Custo Ap√≥s 2870 itera√ß√µes √© 0.2300669970191523\n",
      "Custo Ap√≥s 2880 itera√ß√µes √© 0.22972602765081726\n",
      "Custo Ap√≥s 2890 itera√ß√µes √© 0.22886922910260074\n",
      "Custo Ap√≥s 2900 itera√ß√µes √© 0.22951936889112484\n",
      "Custo Ap√≥s 2910 itera√ß√µes √© 0.229258781910561\n",
      "Custo Ap√≥s 2920 itera√ß√µes √© 0.22940187122110292\n",
      "Custo Ap√≥s 2930 itera√ß√µes √© 0.22839984883237707\n",
      "Custo Ap√≥s 2940 itera√ß√µes √© 0.22852301100340722\n",
      "Custo Ap√≥s 2950 itera√ß√µes √© 0.2271753379074989\n",
      "Custo Ap√≥s 2960 itera√ß√µes √© 0.22798902417217687\n",
      "Custo Ap√≥s 2970 itera√ß√µes √© 0.2277769502748512\n",
      "Custo Ap√≥s 2980 itera√ß√µes √© 0.2284457217795069\n",
      "Custo Ap√≥s 2990 itera√ß√µes √© 0.22637557577599435\n",
      "\n",
      "Treinamento Conclu√≠do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "\n",
    "print(\"\\nIniciando o Treinamento.\\n\")\n",
    "\n",
    "parametros, custo = modeloNN(X = X_treino, \n",
    "                             Y = y_treino, \n",
    "                             dims_camada_entrada = dims_camada_entrada, \n",
    "                             num_iterations = 3000, \n",
    "                             learning_rate = 0.0075)\n",
    "\n",
    "print(\"\\nTreinamento Conclu√≠do.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fbe35151d0>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot do erro durante o treinamento\n",
    "plt.plot(custo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes com os dados de treino\n",
    "y_pred_treino = predict(X_treino, parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04252143e-05, 9.80449778e-04, 8.81171420e-01, 8.81171420e-01,\n",
       "        8.81171420e-01, 7.95468237e-01, 8.81171420e-01, 8.27315633e-01,\n",
       "        8.57058135e-01, 8.47046236e-01, 8.70711789e-01, 8.39631653e-01,\n",
       "        5.60084998e-14, 5.13982262e-01, 8.25076697e-01, 8.80609707e-01,\n",
       "        8.81130454e-01, 4.75650651e-06, 1.16401326e-16, 8.81152305e-01,\n",
       "        8.15207618e-01, 7.98391391e-01, 8.81164378e-01, 8.81171420e-01,\n",
       "        4.97310118e-01, 8.57072144e-01, 8.67721923e-01, 8.81155221e-01,\n",
       "        7.73001734e-01, 7.82706949e-01, 3.42658518e-19, 4.46428516e-18,\n",
       "        5.49933315e-01, 1.64686893e-17, 8.30423217e-01, 2.42219529e-02,\n",
       "        8.81164992e-01, 8.81171420e-01, 8.69573318e-01, 8.21793002e-09,\n",
       "        1.00101509e-05, 8.81171420e-01, 5.29171213e-02, 2.38511280e-18,\n",
       "        8.23860625e-01, 8.79455191e-01, 8.81171420e-01, 1.78869096e-10,\n",
       "        8.81171420e-01, 8.81170346e-01, 1.46299996e-09, 8.81171420e-01,\n",
       "        7.96490913e-01, 8.53550768e-01, 8.81162827e-01, 8.81171420e-01,\n",
       "        8.81171420e-01, 8.18811465e-01, 8.81171420e-01, 7.56873260e-01,\n",
       "        3.67086947e-03, 8.51780525e-01, 8.81171420e-01, 7.43029185e-25,\n",
       "        6.75625594e-04, 8.63652294e-01, 8.81171420e-01, 1.43285238e-10,\n",
       "        3.80172279e-05, 8.81171420e-01, 8.13545309e-01, 8.61155906e-01,\n",
       "        8.78698037e-01, 1.89034881e-07, 8.63960340e-01, 5.85999686e-01,\n",
       "        8.81167529e-01, 2.36139166e-04, 3.60106150e-01, 8.81171420e-01,\n",
       "        1.99425036e-04, 8.81171420e-01, 6.08748412e-01, 8.81171420e-01,\n",
       "        2.54878770e-14, 5.69406076e-03, 8.81171420e-01, 1.07879973e-03,\n",
       "        8.81171420e-01, 3.78834309e-14, 5.66764920e-01, 8.81171420e-01,\n",
       "        8.46611705e-01, 8.71659426e-01, 5.79913280e-01, 7.30979910e-01,\n",
       "        8.63922141e-01, 8.30325090e-01, 3.91039110e-01, 8.81171420e-01,\n",
       "        8.81171420e-01, 5.97409789e-01, 5.63072298e-03, 2.31173442e-03,\n",
       "        8.81171420e-01, 8.81159399e-01, 1.46395937e-01, 2.44489570e-01,\n",
       "        7.32654203e-02, 1.40989931e-02, 3.81047133e-01, 1.98344117e-01,\n",
       "        8.60638415e-01, 6.62042525e-01, 8.78273897e-01, 5.78966872e-07,\n",
       "        7.93855015e-01, 5.00680848e-03, 5.12950802e-01, 8.81171420e-01,\n",
       "        8.81155852e-01, 3.62642704e-01, 8.79326329e-01, 1.61726412e-01,\n",
       "        8.81171420e-01, 1.03758737e-01, 5.31734396e-02, 8.15017587e-01,\n",
       "        4.76565211e-03, 8.72352974e-01, 7.78857641e-01, 1.60968778e-01,\n",
       "        2.99195592e-02, 1.44188024e-05, 5.81032109e-01, 1.83413771e-08,\n",
       "        8.65501049e-01, 8.81171420e-01, 8.81171420e-01, 1.40840745e-02,\n",
       "        8.69693590e-01, 5.75001571e-01, 8.81171420e-01, 6.75849835e-12,\n",
       "        3.15002289e-08, 7.87411857e-06, 1.46360535e-01, 1.44514469e-02,\n",
       "        7.21941656e-01, 6.97471137e-01, 8.79279137e-01, 8.60484749e-01,\n",
       "        8.81171420e-01, 8.70260953e-01, 7.55793324e-01, 7.45378703e-01,\n",
       "        7.64267522e-01, 8.81171420e-01, 8.52414511e-01, 8.66807199e-01,\n",
       "        8.81171420e-01, 1.70856669e-01, 1.12880579e-01, 8.81171420e-01,\n",
       "        7.13222572e-01, 7.77085104e-01, 6.24345454e-01, 1.92711328e-03,\n",
       "        8.35335621e-01, 8.81171420e-01, 1.87793244e-02, 8.76688186e-01,\n",
       "        9.20263737e-05, 8.59142750e-01, 8.51638802e-01, 5.46966886e-07,\n",
       "        6.49441919e-01, 8.81171420e-01, 4.49422549e-02, 8.66145396e-01,\n",
       "        8.81171420e-01, 8.81171420e-01, 8.81171420e-01, 1.04720461e-06,\n",
       "        8.02418055e-01, 8.78235933e-01, 8.81156283e-01, 3.75603219e-01,\n",
       "        6.80288104e-01, 5.86368398e-01, 6.51819472e-01, 8.81171420e-01,\n",
       "        6.92103377e-04, 2.48507456e-02, 1.05184703e-09, 4.44269693e-01,\n",
       "        8.19385419e-01, 8.44042127e-01, 8.01477704e-01, 1.24413444e-05,\n",
       "        5.57211769e-04, 5.28165790e-02, 8.05272547e-01, 9.14864457e-07,\n",
       "        8.79190928e-01, 8.55533143e-01, 9.52926104e-18, 6.92435487e-01,\n",
       "        8.81171420e-01, 1.24893734e-01, 5.45011459e-10, 4.27932928e-02,\n",
       "        4.98949501e-04, 1.20696821e-03, 8.81171420e-01, 4.98944514e-06,\n",
       "        8.54852028e-01, 4.92116873e-01, 8.18435538e-01, 6.45205743e-01,\n",
       "        7.21106950e-01, 8.69193825e-01, 8.31837862e-01, 6.59851095e-01,\n",
       "        6.70411119e-01, 8.16949287e-01, 5.89648035e-04, 7.54363449e-06,\n",
       "        7.00311018e-01, 8.07850220e-01, 1.65174863e-01, 2.76416564e-08,\n",
       "        8.81171420e-01, 8.26423721e-01, 8.72558703e-01, 8.81171420e-01,\n",
       "        8.54703287e-01, 8.30767880e-01, 8.81171420e-01, 8.81163093e-01,\n",
       "        7.44925260e-01, 8.81171420e-01, 8.81171420e-01, 1.20987869e-04,\n",
       "        3.73436887e-31, 8.81171420e-01, 8.10563389e-01, 1.74770735e-06,\n",
       "        8.48300100e-01, 7.22321651e-01, 6.75593248e-01, 2.44158101e-03,\n",
       "        8.81130143e-01, 2.94967631e-16, 5.11013571e-13, 1.69810407e-13,\n",
       "        8.52293715e-01, 8.81171420e-01, 5.45519542e-01, 8.81171420e-01,\n",
       "        7.84182161e-01, 1.65050970e-02, 7.57195744e-01, 8.71978604e-01,\n",
       "        8.01469128e-01, 1.91422987e-05, 8.77821707e-01, 8.42719725e-01,\n",
       "        6.53853610e-05, 4.12233119e-07, 3.19078366e-02, 8.81171420e-01,\n",
       "        7.69157128e-04, 2.08422451e-07, 3.73016521e-01, 8.81171420e-01,\n",
       "        8.20478104e-01, 8.81171420e-01, 7.75754398e-01, 8.74093261e-01,\n",
       "        8.57581432e-01, 8.77481870e-01, 3.59274987e-09, 8.81171420e-01,\n",
       "        8.00361592e-01, 8.18324779e-01, 1.16519151e-08, 2.86853406e-04,\n",
       "        3.29804219e-02, 8.22587076e-01, 7.20469336e-01, 1.91883726e-01,\n",
       "        8.81171420e-01, 4.21163078e-05, 2.85858202e-06, 8.81171420e-01,\n",
       "        1.27567457e-04, 6.94289745e-01, 8.73785872e-01, 8.81158127e-01,\n",
       "        8.72091421e-01, 8.81171420e-01, 8.49485580e-01, 8.16214541e-01,\n",
       "        8.81171420e-01, 5.90417807e-04, 8.65470067e-01, 1.55662885e-01,\n",
       "        2.93700179e-01, 8.39945167e-03, 8.81171420e-01, 2.75478319e-01,\n",
       "        1.28534511e-01, 8.65520727e-10, 6.78330222e-07, 5.28682734e-01,\n",
       "        8.17672349e-01, 2.37752553e-05, 5.76583679e-12, 8.81171420e-01,\n",
       "        4.62406930e-06, 8.60615041e-01, 8.50183788e-01, 8.81171420e-01,\n",
       "        6.84132470e-11, 8.81171420e-01, 8.72996751e-01, 7.81561924e-01,\n",
       "        5.56917426e-06, 8.81171420e-01, 8.48636688e-01, 8.66270533e-01,\n",
       "        8.81171420e-01, 8.24932918e-01, 7.44411847e-01, 8.76511661e-01,\n",
       "        8.81168776e-01, 1.11427477e-03, 3.87691499e-03, 2.77707124e-02,\n",
       "        6.55788559e-01, 6.57703034e-01, 8.76581311e-01, 8.81171420e-01,\n",
       "        8.81166640e-01, 3.22036534e-02, 1.28387758e-01, 8.81171420e-01,\n",
       "        7.78924282e-01, 3.95366607e-09, 8.81171420e-01, 1.06730261e-03,\n",
       "        8.73949439e-01, 1.92558881e-10, 1.56433585e-06, 8.81171420e-01,\n",
       "        2.80816661e-07, 5.62162209e-01, 8.81171420e-01, 8.81171420e-01,\n",
       "        7.34107626e-01, 1.39304336e-06, 3.09887493e-01, 8.81171420e-01,\n",
       "        6.86786015e-01, 3.19230759e-08, 2.62439296e-02, 7.82235122e-01,\n",
       "        5.92945862e-01, 8.54036149e-01, 8.81171420e-01, 8.81171420e-01,\n",
       "        7.74982653e-04, 8.81171420e-01, 8.81171420e-01, 6.15004108e-01,\n",
       "        3.07538564e-06, 8.43746147e-01, 8.79303370e-01, 7.37197993e-01,\n",
       "        8.81171420e-01, 8.76205801e-01, 8.81171420e-01, 8.74146804e-01,\n",
       "        3.02925889e-03, 8.81171420e-01, 6.18737564e-01, 5.45577213e-02,\n",
       "        2.07466781e-01, 1.48885785e-30, 8.68929636e-01, 4.68374830e-06,\n",
       "        8.80810645e-01, 8.81170394e-01, 8.81171420e-01, 8.70258391e-01,\n",
       "        2.20557047e-01, 8.81171420e-01, 8.76492398e-01, 7.69468452e-01,\n",
       "        9.67067526e-05, 8.81171420e-01, 7.69999875e-01, 8.81171420e-01,\n",
       "        4.25473063e-01, 2.05702630e-04, 8.81171420e-01, 7.18634012e-03,\n",
       "        8.81164102e-01, 1.76255500e-05, 1.32613808e-18, 8.81171420e-01,\n",
       "        5.26700038e-01, 2.17621235e-02, 5.14334825e-01, 8.81171420e-01,\n",
       "        8.81171420e-01, 2.14142868e-05, 8.70236543e-01, 9.52640558e-09,\n",
       "        6.39420863e-01, 8.81171420e-01, 8.81171420e-01, 8.81171420e-01,\n",
       "        8.81166722e-01, 8.81171420e-01, 9.42172584e-07, 1.25483439e-02,\n",
       "        1.71473012e-01, 7.62849748e-01, 1.78674141e-07, 4.82689505e-01,\n",
       "        7.11094717e-01, 6.84148210e-01, 8.63804499e-01, 8.41742820e-01,\n",
       "        9.46980063e-03, 5.64479340e-11, 5.71443931e-03, 8.81171420e-01,\n",
       "        6.00831336e-10, 3.62254937e-01, 8.81171420e-01, 7.95422093e-01,\n",
       "        3.21478076e-01, 7.49804662e-05, 4.96457957e-06, 7.13412855e-01,\n",
       "        5.73108618e-05, 8.64844997e-01, 7.59551272e-01, 7.30339877e-01,\n",
       "        1.86142013e-10, 4.53023089e-03, 8.81171420e-01, 7.03017786e-01,\n",
       "        5.53866784e-01, 2.16056691e-06, 8.81171420e-01, 8.81171420e-01,\n",
       "        7.98790771e-01, 8.11876593e-01, 8.81171420e-01, 8.81165600e-01,\n",
       "        8.13717220e-01, 6.44959863e-01, 7.65051786e-10, 7.85705448e-01,\n",
       "        1.92529227e-06, 1.14459136e-01, 8.81171420e-01, 1.37156464e-01,\n",
       "        8.81171420e-01, 8.08033717e-01, 8.75917924e-01, 8.38345563e-01,\n",
       "        3.20978529e-12, 1.86835293e-03, 8.81167356e-01, 8.21994371e-01,\n",
       "        4.66128798e-01, 2.01448190e-06, 8.81171420e-01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza as previs√µes\n",
    "y_pred_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos o shape em treino\n",
    "y_pred_treino = y_pred_treino.reshape(-1)\n",
    "y_treino = y_treino.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False, False,  True, False,  True, False,\n",
       "        True,  True,  True, False, False,  True, False, False,  True,\n",
       "        True,  True, False,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False,  True,  True, False, False,  True,  True,  True,\n",
       "        True, False,  True,  True,  True, False, False,  True, False,\n",
       "        True,  True,  True, False, False,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True,  True,  True, False,  True,\n",
       "       False,  True,  True,  True, False,  True, False,  True, False,\n",
       "       False,  True, False,  True,  True, False, False, False,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True, False,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True, False,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False, False, False, False,  True,  True,\n",
       "        True, False, False, False,  True, False,  True,  True, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True, False,  True,  True,  True, False,\n",
       "        True, False, False, False,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True, False, False,\n",
       "       False,  True, False, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False, False,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False, False, False,  True, False, False, False, False,\n",
       "        True,  True, False, False,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True, False,  True,\n",
       "       False,  True, False, False,  True, False,  True,  True,  True,\n",
       "        True, False, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False, False,  True, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True, False,\n",
       "       False,  True, False,  True, False, False,  True,  True, False,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False,  True, False, False,\n",
       "        True,  True,  True,  True, False, False, False,  True, False,\n",
       "       False,  True,  True, False, False, False,  True, False,  True,\n",
       "        True,  True, False, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False, False,  True, False,  True,  True,  True,  True, False,\n",
       "       False,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_treino > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertemos as previs√µes para o valor bin√°rio de classe \n",
    "# (0 ou 1, usando como threshold o valor de 0.5 da probabilidade)\n",
    "y_pred_treino = 1 * (y_pred_treino > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos a acur√°cia comparando valor real com valor previsto\n",
    "acc_treino = sum(1 * (y_pred_treino == y_treino)) / len(y_pred_treino) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia nos dados de treino: 92.13250517598344\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur√°cia nos dados de treino: \" + str(acc_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Maligno       0.91      0.88      0.89       182\n",
      "     Benigno       0.93      0.95      0.94       301\n",
      "\n",
      "    accuracy                           0.92       483\n",
      "   macro avg       0.92      0.91      0.92       483\n",
      "weighted avg       0.92      0.92      0.92       483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_treino, y_pred_treino, target_names = ['Maligno', 'Benigno']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes com o modelo usando dados de teste\n",
    "y_pred_teste = predict(X_teste, parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.77596783e-01, 7.75351173e-03, 1.32535131e-02, 8.43658255e-01,\n",
       "        4.23220304e-15, 8.81171420e-01, 8.72869058e-01, 8.81160707e-01,\n",
       "        7.15122762e-01, 2.45076394e-09, 5.15298469e-01, 7.15798004e-06,\n",
       "        8.81171420e-01, 7.57840818e-01, 2.43048169e-01, 8.81145361e-01,\n",
       "        8.55951233e-01, 7.46693779e-01, 8.18950832e-01, 1.45358840e-07,\n",
       "        8.68635859e-01, 1.01571666e-05, 8.81171420e-01, 8.81171420e-01,\n",
       "        3.08169804e-04, 1.51468758e-06, 8.81171420e-01, 4.74390057e-06,\n",
       "        9.79983346e-05, 8.76615947e-01, 8.81171420e-01, 8.81171420e-01,\n",
       "        8.76592166e-01, 1.09204855e-06, 5.47138108e-01, 5.46076489e-02,\n",
       "        8.81171420e-01, 8.64598595e-01, 1.12777170e-06, 2.34023890e-03,\n",
       "        1.57435778e-01, 1.07912059e-01, 5.93716538e-03, 7.72570828e-01,\n",
       "        8.81170427e-01, 3.29680774e-05, 8.81171420e-01, 8.80863099e-01,\n",
       "        7.77553835e-01, 8.81171420e-01, 8.81162149e-01, 8.55529089e-01,\n",
       "        8.81100064e-01, 1.78890057e-04, 8.81171420e-01, 2.59750318e-05,\n",
       "        7.69081619e-01, 1.67821565e-05, 8.42854572e-01, 8.81171420e-01,\n",
       "        6.85384196e-01, 7.68542280e-01, 8.81171420e-01, 8.28089380e-01,\n",
       "        7.80812357e-01, 8.70657840e-01, 8.75647514e-01, 4.32853794e-05,\n",
       "        8.81171420e-01, 8.04761771e-01, 7.91959931e-01, 1.09033444e-02,\n",
       "        7.38103442e-04, 5.20141469e-02, 8.81171420e-01, 6.89273517e-01,\n",
       "        4.29132282e-05, 6.11203382e-05, 8.36589777e-01, 8.16793931e-01,\n",
       "        3.19140001e-01, 3.85423854e-03, 6.89064956e-01, 4.29548119e-01,\n",
       "        2.74180783e-02, 8.36875612e-01]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados\n",
    "y_pred_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos os shapes\n",
    "y_pred_teste = y_pred_teste.reshape(-1)\n",
    "y_teste = y_teste.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertemos as previs√µes para o valor bin√°rio de classe\n",
    "y_pred_teste = 1 * (y_pred_teste > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos as previs√µes\n",
    "y_pred_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos a acur√°cia\n",
    "acuracia = sum(1 * (y_pred_teste == y_teste)) / len(y_pred_teste) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia nos dados de teste: 91.86046511627907\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur√°cia nos dados de teste: \" + str(acuracia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Maligno       0.85      0.93      0.89        30\n",
      "     Benigno       0.96      0.91      0.94        56\n",
      "\n",
      "    accuracy                           0.92        86\n",
      "   macro avg       0.91      0.92      0.91        86\n",
      "weighted avg       0.92      0.92      0.92        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste, y_pred_teste, target_names = ['Maligno', 'Benigno']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o\n",
    "\n",
    "Neste notebook, implementamos uma rede neural do zero utilizando apenas opera√ß√µes matem√°ticas e a biblioteca NumPy. Passamos por todas as etapas fundamentais do funcionamento de uma rede neural, incluindo a inicializa√ß√£o dos pesos, forward propagation, c√°lculo da fun√ß√£o de perda, backpropagation e atualiza√ß√£o dos pesos com gradiente descendente.\n",
    "\n",
    "Ao construir a rede manualmente, conseguimos visualizar como cada etapa contribui para o aprendizado do modelo, oferecendo uma compreens√£o mais profunda do que acontece por tr√°s dos frameworks populares como TensorFlow e PyTorch.\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "Se quiser expandir este projeto, aqui est√£o algumas sugest√µes:\n",
    "\n",
    "- Implementar outras fun√ß√µes de ativa√ß√£o, como Tanh ou Leaky ReLU.\n",
    "- Testar diferentes fun√ß√µes de perda para problemas espec√≠ficos.\n",
    "- Adicionar suporte para m√∫ltiplas camadas ocultas e diferentes quantidades de neur√¥nios.\n",
    "- Explorar t√©cnicas de otimiza√ß√£o mais avan√ßadas, como Adam ou RMSprop.\n",
    "\n",
    "Essa abordagem did√°tica permite uma base s√≥lida para quem deseja avan√ßar no estudo de redes neurais e machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
